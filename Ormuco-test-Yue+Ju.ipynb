{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question A\n",
    "#Your goal for this question is to write a program that accepts two lines (x1,x2) and (x3,x4) on the x-axis and \n",
    "#returns whether they overlap. As an example, (1,5) and (2,6) overlaps but not (1,5) and (6,8).\n",
    "import sys\n",
    "line1=(1,5)\n",
    "line2=(2,6)\n",
    "line3=()\n",
    "line4=(6,8)\n",
    "line5=(2,5)\n",
    "line6=(5,2)\n",
    "def check_overlap(line1,line2):\n",
    "    #check empty\n",
    "    if len(line1)==0 or len(line2)==0:\n",
    "        print('error, empty tuple')\n",
    "        sys.exit('line cannot be empty')\n",
    "    else:\n",
    "        #e.g if tuple is (2,1) change it to (1,2)\n",
    "        line1=swap(line1[0],line1[1])\n",
    "        print(line1)\n",
    "        line2=swap(line2[0],line2[1])\n",
    "        print(line2)\n",
    "        #check which one infront of which e.g(1,1) infront of (1,2)\n",
    "        if line1[0]<=line2[0]:\n",
    "            if line1[1]<line2[0]:\n",
    "                return \"no\"\n",
    "            else:\n",
    "                return \"yes\"\n",
    "        else:\n",
    "            if line2[1]<line1[0]:\n",
    "                return \"no\"\n",
    "            else:\n",
    "                return \"yes\"                \n",
    "#swap tuple        \n",
    "def swap(a, b):\n",
    "    if a>b:\n",
    "        return (b, a)\n",
    "    else:\n",
    "        return (a, b)\n",
    "#check  \n",
    "#check_overlap(line1,line2)\n",
    "#check_overlap(line2,line1)\n",
    "#check_overlap(line1,line3)\n",
    "#check_overlap(line3,line3)\n",
    "#check_overlap(line1,line4)\n",
    "#check_overlap(line2,line5)\n",
    "#check_overlap(line2,line6)\n",
    "#check_overlap(line5,line1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question B\n",
    "#The goal of this question is to write a software library that accepts 2 version string as input and returns \n",
    "#whether one is greater than, equal, or less than the other. \n",
    "#As an example: “1.2” is greater than “1.1”. Please provide all test cases you could think of.\n",
    "import re\n",
    "def compare_ver(v1, v2):\n",
    "    #Use regular expressions to determine if the version number format is correct\n",
    "    #The version number contains non-numbers\n",
    "    v1match = re.match(\"\\d+(\\.\\d+){0,2}\", v1)\n",
    "    v2match = re.match(\"\\d+(\\.\\d+){0,2}\", v2)\n",
    "    #print(v1)\n",
    "    #print(v2)\n",
    "    #The version number is empty\n",
    "    if len(v1)==0 or len(v2)==0:\n",
    "        sys.exit('empty version string')\n",
    "    if v1match is None or v2match is None:\n",
    "        sys.exit('wrong input')\n",
    "    #split by .\n",
    "    l_v1 = v1.split(\".\")\n",
    "    l_v2 = v2.split(\".\")\n",
    "    #calculate lenth of each list\n",
    "    l_v1_len = len(l_v1)\n",
    "    l_v2_len = len(l_v2)\n",
    "    len_diff=abs(l_v1_len-l_v2_len)\n",
    "    #Compare array lengths, fill short arrays with \"0\" into equal length arrays\n",
    "    if l_v1_len > l_v2_len:\n",
    "        for i in range(len_diff):\n",
    "            l_v2.append(\"0\")\n",
    "    elif l_v2_len > l_v1_len:\n",
    "        for i in range(len_diff):\n",
    "            l_v1.append(\"0\")\n",
    "    else:\n",
    "        pass\n",
    "    # compare two ver of strings\n",
    "    for i in range(len(l_v1)):\n",
    "        if int(l_v1[i]) > int(l_v2[i]):\n",
    "            return \"v1 is biger than v2\"\n",
    "        if int(l_v1[i]) < int(l_v2[i]):\n",
    "            return \"v2 is bigger than v1\"\n",
    "    return \"v1 and v2 are equal\"\n",
    "\n",
    "\n",
    "#test case\n",
    "#1.empty string\n",
    "#print(compare_ver(v1=\"\", v2=\"\"))\n",
    "#2.contains non- numbers\n",
    "#print(compare_ver(v1=\"a.a.a\", v2=\"b.b.b\"))\n",
    "#3.equal versions\n",
    "#print(compare_ver(v1=\"1.0\", v2=\"1.0\"))\n",
    "#4.v2 is bigger than v1\n",
    "#print(compare_ver(v1=\"1.0\", v2=\"1.2\"))\n",
    "#5.v1 is bigger than v2\n",
    "#print(compare_ver(v1=\"1.0.5\", v2=\"1.0.2\"))\n",
    "#6.len of v1 is bigger than v2 and v1 is bigger than v2\n",
    "#print(compare_ver(v1=\"1.0.11\", v2=\"1.0\"))\n",
    "#7.len of v1 is bigger than v2 and v2 is bigger than v1\n",
    "#print(compare_ver(v1=\"1.0.11\", v2=\"1.2\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question C\n",
    "\n",
    "#suppose we have three servernodes(different Geo)\n",
    "VM1 Centos: 40.85.209.47\n",
    "VM2 Centos: 40.85.210.123\n",
    "VM3 Centos: 13.71.166.230\n",
    "\n",
    "#Distrubuted our data across Geolocation, using MongoDB to achieve this goal, because MongoDB is NoSQL and flexible with Schema\n",
    "#solved- \n",
    "# 1 - Simplicity. Integration needs to be dead simple. \n",
    "# 2 - Resilient to network failures or crashes by replication and sharding\n",
    "# 4 - Data consistency across regions\n",
    "# 5 - Locality of reference, data should almost always be available from the closest region\n",
    "# distributed database\n",
    "# 6 - Flexible Schema\n",
    "\n",
    "#replication&sharding:\n",
    "select VM1 to be masternode and others to be secondarynode, master node has the highest priority and write can\n",
    "only be done in masternode. secondarynodes are for read. If any master node fails, secondarynode will vote for a new\n",
    "master node.\n",
    "\n",
    "#Geo location:\n",
    "MongoDB provides geo location search functionality by default\n",
    "\n",
    "#Consistency:\n",
    "MongoDB can also keep data consistency(Bank transactions) or eventually consistency(some operations not requie high consistency)\n",
    "\n",
    "#Use python to get data from MongoDB, something like:\n",
    "client = MongoClient('mongodb://13.71.166.230,40.85.210.123,40.85.209.47')#connect mongo sharding cluster\n",
    "db = client.ormuco\n",
    "query1=[{'$group':{'_id':\"$UserID\",'total':{'$sum':1}}}]\n",
    "result=db.ratings.aggregate(query1)    \n",
    "    \n",
    "#to access MongoDB, I created API by using Flask:\n",
    "from flask import Flask, jsonify\n",
    "from flask_pymongo import PyMongo\n",
    "from bson.json_util import dumps\n",
    "app = Flask(__name__)\n",
    "app.config[\"MONGO_URI\"] = \"mongodb://13.71.165.114:27017/ormuco\"\n",
    "mongo = PyMongo(app)\n",
    "tasks = dumps(mongo.db.tasks.find().limit(5))\n",
    "@app.route(\"/todo/api/v1.0/tasks\",methods=['GET'])\n",
    "def tasks_func():\n",
    "    return jsonify({'tasks':tasks})\n",
    "\n",
    "\n",
    "\n",
    "#LRUcache Use the list to record the key order, each time setting, or GET operation to insert the key \n",
    "#into the top of the list.\n",
    "#After the buffer is full, the setting operation will appear and the key at the end will be removed.\n",
    "#solved-   # 7 - Cache can expire\n",
    "class LRUcache:\n",
    "def __init__(self, size=3):\n",
    "    self.cache = {}\n",
    "    self.keys = []\n",
    "    self.size = size\n",
    "\n",
    "def get(self, key):\n",
    "    if key in self.cache:\n",
    "        self.keys.remove(key)\n",
    "        self.keys.insert(0, key)\n",
    "        return self.cache[key]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def set(self, key, value):\n",
    "    if key in self.cache:\n",
    "        self.keys.remove(key)\n",
    "        self.keys.insert(0, key)\n",
    "        self.cache[key] = value\n",
    "    elif len(self.keys) == self.size:\n",
    "        old = self.keys.pop()\n",
    "        self.cache.pop(old)\n",
    "        self.keys.insert(0, key)\n",
    "        self.cache[key] = value\n",
    "    else:\n",
    "        self.keys.insert(0, key)\n",
    "        self.cache[key] = value\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test = LRUcache()\n",
    "    test.set('test1',2)\n",
    "    test.set('test2',2)\n",
    "    test.set('test3',2)\n",
    "    test.set('test4',2)\n",
    "    test.set('test5',2)\n",
    "    test.set('test6',2)\n",
    "    print(test.get('test1'))\n",
    "    print(test.get('test2'))\n",
    "    print(test.get('test3'))\n",
    "    \n",
    "#For real-time processing, kafka+spark streaming(near real time processing,but not actually real-time) is another good choice\n",
    "#Kafka will be the Cache part\n",
    "#Flink will be suitable for real time processing\n",
    "#Deployed Apache NIFI to create and manage different data flows for large amount of data\n",
    "#Split and routed the file lines into topics, then published to Kafka Publishers\n",
    "#Built Consumers for each Kafka topic and connect them to Flume sink on MongoDB\n",
    "#Could also Started Oozie coordinator to apply Spark Streaming \n",
    "#e.g (counting item number of each topic, scripting by PySpark), and kept sinking the results to Kafka with a new topic “result”\n",
    "#Final sink the records within the Kafka \"Result\" topic to HDFS or Cassandra DB or MongoDB\n",
    "\n",
    "#code will be something like this\n",
    "from pyspark.streaming \n",
    "import StreamingContext \n",
    "from pyspark.streaming.kafka \n",
    "import KafkaUtils from pyspark \n",
    "import SparkContext\n",
    "from kafka import SimpleProducer, KafkaClient from kafka \n",
    "import KafkaProducer\n",
    "# This producer is to sink data back to new topic: Result\n",
    "k_Producer = KafkaProducer(bootstrap_servers='sandbox-hdp.hortonworks.com:6667') \n",
    "def handler(message):\n",
    "    records = message.collect() for record in records:\n",
    "    producer.send('Result', str(record)) producer.flush()\n",
    "# Create Spark Context\n",
    "sc = SparkContext(appName=\"kafka\") ssc=StreamingContext(sc,5)\n",
    "#connect zookeeper zookeeper=\"sandbox-hdp.hortonworks.com:2181\"\n",
    "# Get data from each Kafka topic: Error and Warn #Topic keywords: Error, Warn. Partition set to 1 Error_topic={\"Error\":1}\n",
    "Warn_topic={\"Warn\":1}\n",
    "Error_groupid=\"10\"\n",
    "Warn_groupid=\"10\"\n",
    "#For Error,get data stream and transform to Error, number, timestamp\n",
    "Error_records = KafkaUtils.createStream(ssc, zookeeper,Error_groupid,Error_topic) \n",
    "Error_records=Error_records.map(lambda x: (\"Error\", 0)).countByWindow(60,5).map(lambda x:(\"Error\",(x,datetime.datetime.now())))\n",
    "#For Error,get data stream and transform to Warn, number, timestamp\n",
    "Warn_records = KafkaUtils.createStream(ssc, zookeeper,Warn_groupid,Warn_topic) \n",
    "Warn_records=Warn_records.map(lambda x: (\"Warn\", 1)).countByWindow(60,5).map(lambda x:(\"Warn\",(x,datetime.datetime.now())))\n",
    "comebine_list = [Warn_lines,Error_lines]\n",
    "lines = ssc.union(*comebine_list)\n",
    "lines.pprint()\n",
    "lines.foreachRDD(handler) #output to HDFS for backup ssc.checkpoint(\"/tmp/checkpoint\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
